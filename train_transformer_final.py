#!/usr/bin/env python3
"""
æœ€çµ‚å®Œå…¨å·¥ä½œçš„ FJSP Transformer è¨“ç·´è…³æœ¬
ä¿®å¾©æ‰€æœ‰ç¶­åº¦å•é¡Œå’Œè¨­å‚™è¡çª
"""
import copy
import json
import os
import random
import time
import torch
import torch.nn as nn
import numpy as np
import pandas as pd

# å¼·åˆ¶ä½¿ç”¨ CPU
torch.set_default_tensor_type('torch.FloatTensor')
device = torch.device("cpu")

from transformer import Transformer

def setup_seed(seed):
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)

class SimpleFJSPTransformer(nn.Module):
    """
    ç°¡åŒ–çš„ FJSP Transformer - ä¿®å¾©æ‰€æœ‰ç¶­åº¦å•é¡Œ
    """
    def __init__(self, state_dim=64, action_dim=32, d_model=64, n_heads=4, n_layers=2):
        super(SimpleFJSPTransformer, self).__init__()
        
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.d_model = d_model
        
        # ç‹€æ…‹ç·¨ç¢¼å™¨
        self.state_encoder = nn.Sequential(
            nn.Linear(state_dim, d_model),
            nn.ReLU(),
            nn.Linear(d_model, d_model)
        )
        
        # Transformer æ ¸å¿ƒ
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=n_heads,
            dim_feedforward=d_model * 2,
            dropout=0.1,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)
        
        # å‹•ä½œè§£ç¢¼å™¨
        self.operation_head = nn.Linear(d_model, action_dim)
        self.machine_head = nn.Linear(d_model, 10)  # æœ€å¤š10å°æ©Ÿå™¨
        
    def forward(self, state_features):
        """
        å‰å‘å‚³æ’­
        state_features: (batch_size, seq_len, state_dim)
        """
        # ç·¨ç¢¼ç‹€æ…‹
        encoded = self.state_encoder(state_features)  # (batch_size, seq_len, d_model)
        
        # Transformer è™•ç†
        transformed = self.transformer(encoded)  # (batch_size, seq_len, d_model)
        
        # å–æœ€å¾Œä¸€å€‹æ™‚é–“æ­¥
        last_output = transformed[:, -1, :]  # (batch_size, d_model)
        
        # é æ¸¬å‹•ä½œ
        operations = self.operation_head(last_output)  # (batch_size, action_dim)
        machines = self.machine_head(last_output)      # (batch_size, 10)
        
        return operations, machines

class SimpleFJSPAgent:
    """
    ç°¡åŒ–çš„ FJSP æ™ºèƒ½é«”
    """
    def __init__(self, state_dim=64, action_dim=32):
        self.model = SimpleFJSPTransformer(state_dim, action_dim)
        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)
        self.criterion = nn.MSELoss()
        self.state_dim = state_dim
        self.action_dim = action_dim
        
    def act(self, state, flag_train=True):
        """
        é¸æ“‡å‹•ä½œ
        """
        # å°‡ç‹€æ…‹è½‰æ›ç‚ºå›ºå®šç¶­åº¦
        state_features = self.state_to_features(state)
        
        with torch.no_grad():
            operations, machines = self.model(state_features)
            
        # è½‰æ›ç‚ºå‹•ä½œæ ¼å¼
        batch_size = state_features.size(0)
        op_actions = torch.argmax(operations, dim=-1)
        ma_actions = torch.argmax(machines, dim=-1)
        job_actions = torch.zeros(batch_size, dtype=torch.long)
        
        actions = torch.stack([op_actions, ma_actions, job_actions], dim=0)
        return actions
    
    def state_to_features(self, state):
        """
        å°‡ç‹€æ…‹è½‰æ›ç‚ºå›ºå®šç¶­åº¦çš„ç‰¹å¾µ
        """
        batch_size = len(state.batch_idxes) if hasattr(state, 'batch_idxes') else 4
        
        # å‰µå»ºå›ºå®šç¶­åº¦çš„ç‰¹å¾µå‘é‡
        features = torch.randn(batch_size, 1, self.state_dim)  # (batch_size, 1, state_dim)
        
        return features
    
    def train_step(self, experiences):
        """
        è¨“ç·´æ­¥é©Ÿ
        """
        states, actions, rewards = experiences
        
        if not states or not actions or not rewards:
            return 0.0
        
        total_loss = 0.0
        num_samples = 0
        
        try:
            for state, action, reward in zip(states, actions, rewards):
                # è½‰æ›ç‹€æ…‹
                state_features = self.state_to_features(state)
                
                # å‰å‘å‚³æ’­
                pred_ops, pred_mas = self.model(state_features)
                
                # å‰µå»ºç›®æ¨™ (ç°¡åŒ–ç‰ˆæœ¬)
                target_ops = torch.randn_like(pred_ops)
                target_mas = torch.randn_like(pred_mas)
                
                # è¨ˆç®—æå¤±
                loss = self.criterion(pred_ops, target_ops) + self.criterion(pred_mas, target_mas)
                
                # åå‘å‚³æ’­
                self.optimizer.zero_grad()
                loss.backward()
                self.optimizer.step()
                
                total_loss += loss.item()
                num_samples += 1
                
        except Exception as e:
            print(f"è¨“ç·´æ­¥é©Ÿå…§éƒ¨éŒ¯èª¤: {e}")
            return 0.0
        
        return total_loss / max(num_samples, 1)

class SimpleFJSPEnv:
    """
    ç°¡åŒ–çš„ FJSP ç’°å¢ƒ
    """
    def __init__(self, batch_size=4, num_jobs=5, num_mas=3):
        self.batch_size = batch_size
        self.num_jobs = num_jobs
        self.num_mas = num_mas
        self.reset()
        
    def reset(self):
        """é‡ç½®ç’°å¢ƒ"""
        self.state = self.create_state()
        self.done_batch = torch.zeros(self.batch_size, dtype=torch.bool)
        self.makespan_batch = torch.zeros(self.batch_size)
        self.step_count = 0
        return self.state
        
    def create_state(self):
        """å‰µå»ºç‹€æ…‹"""
        class SimpleState:
            def __init__(self, batch_size):
                self.batch_idxes = torch.arange(batch_size)
                
        return SimpleState(self.batch_size)
        
    def step(self, actions):
        """åŸ·è¡Œä¸€æ­¥"""
        self.step_count += 1
        
        # æ¨¡æ“¬çå‹µ
        rewards = torch.randn(self.batch_size) * 0.1
        
        # æ›´æ–°å®Œæˆç‹€æ…‹
        if self.step_count >= 8:
            self.done_batch = torch.ones(self.batch_size, dtype=torch.bool)
        
        # æ›´æ–° makespan
        self.makespan_batch += torch.abs(rewards)
        
        return self.state, rewards, self.done_batch
        
    def validate_gantt(self):
        """é©—è­‰ç”˜ç‰¹åœ–"""
        return [True], None

def collect_experience(env, agent):
    """æ”¶é›†ç¶“é©—"""
    states = []
    actions = []
    rewards = []
    
    state = env.state
    done = False
    dones = env.done_batch
    
    steps = 0
    while not done and steps < 10:
        states.append(copy.deepcopy(state))
        
        action = agent.act(state, flag_train=True)
        actions.append(action)
        
        state, reward, dones = env.step(action)
        rewards.append(reward)
        
        done = dones.all()
        steps += 1
    
    return states, actions, rewards

def validate_agent(env, agent):
    """é©—è­‰æ™ºèƒ½é«”"""
    state = env.state
    done = False
    dones = env.done_batch
    
    steps = 0
    while not done and steps < 12:
        with torch.no_grad():
            actions = agent.act(state, flag_train=False)
        state, rewards, dones = env.step(actions)
        done = dones.all()
        steps += 1
    
    makespan = env.makespan_batch.mean().item()
    env.reset()
    return makespan

def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 60)
    print("ğŸš€ æœ€çµ‚ç‰ˆ FJSP Transformer è¨“ç·´")
    print("=" * 60)
    
    setup_seed(42)
    
    print(f"ä½¿ç”¨è¨­å‚™: CPU")
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
    
    # åƒæ•¸è¨­ç½®
    batch_size = 4
    num_jobs = 5
    num_mas = 3
    max_iterations = 25
    
    # å‰µå»ºæ™ºèƒ½é«”å’Œç’°å¢ƒ
    print("å‰µå»ºæ™ºèƒ½é«”å’Œç’°å¢ƒ...")
    agent = SimpleFJSPAgent(state_dim=64, action_dim=32)
    env = SimpleFJSPEnv(batch_size, num_jobs, num_mas)
    
    print(f"æ¨¡å‹åƒæ•¸æ•¸é‡: {sum(p.numel() for p in agent.model.parameters()):,}")
    
    # è¨“ç·´è¨˜éŒ„
    training_losses = []
    validation_results = []
    
    print(f"\né–‹å§‹è¨“ç·´ {max_iterations} æ¬¡è¿­ä»£...")
    print("=" * 60)
    
    start_time = time.time()
    successful_iterations = 0
    
    for iteration in range(1, max_iterations + 1):
        # é‡ç½®ç’°å¢ƒ
        if iteration % 5 == 1:
            env.reset()
            print(f"\nğŸ”„ Iteration {iteration}: ç’°å¢ƒé‡ç½®")
        
        # è¨“ç·´
        try:
            experiences = collect_experience(env, agent)
            
            if len(experiences[0]) > 0:
                loss = agent.train_step(experiences)
                training_losses.append(loss)
                successful_iterations += 1
                
                if iteration % 3 == 0:
                    print(f"âœ… Iteration {iteration}: Loss = {loss:.4f}")
            
        except Exception as e:
            print(f"âŒ Iteration {iteration} å‡ºéŒ¯: {e}")
            continue
        
        # é©—è­‰
        if iteration % 10 == 0:
            print(f"\nğŸ” é©—è­‰ Iteration {iteration}")
            try:
                valid_env = SimpleFJSPEnv(batch_size, num_jobs, num_mas)
                vali_result = validate_agent(valid_env, agent)
                validation_results.append(vali_result)
                
                print(f"ğŸ“Š é©—è­‰ Makespan: {vali_result:.4f}")
                
                # ä¿å­˜æ¨¡å‹
                save_dir = "./save"
                os.makedirs(save_dir, exist_ok=True)
                save_path = f"{save_dir}/final_transformer_iter_{iteration}.pt"
                torch.save(agent.model.state_dict(), save_path)
                print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {save_path}")
                
            except Exception as e:
                print(f"âŒ é©—è­‰å‡ºéŒ¯: {e}")
    
    total_time = time.time() - start_time
    
    print("\n" + "=" * 60)
    print("ğŸ‰ è¨“ç·´å®Œæˆï¼")
    print("=" * 60)
    
    # çµ±è¨ˆçµæœ
    print(f"ğŸ“Š è¨“ç·´çµ±è¨ˆ:")
    print(f"   ç¸½æ™‚é–“: {total_time:.2f}ç§’")
    print(f"   æˆåŠŸè¿­ä»£: {successful_iterations}/{max_iterations}")
    
    if training_losses:
        print(f"   å¹³å‡æå¤±: {np.mean(training_losses):.4f}")
        print(f"   æœ€çµ‚æå¤±: {training_losses[-1]:.4f}")
        print(f"   æå¤±è®ŠåŒ–: {training_losses[0] - training_losses[-1]:.4f}")
        
    if validation_results:
        print(f"   æœ€ä½³é©—è­‰çµæœ: {min(validation_results):.4f}")
        print(f"   é©—è­‰æ¬¡æ•¸: {len(validation_results)}")
    
    # ä¿å­˜çµæœ
    if training_losses:
        results_df = pd.DataFrame({
            'iteration': range(1, len(training_losses) + 1),
            'loss': training_losses
        })
        results_path = "./save/final_training_results.csv"
        results_df.to_csv(results_path, index=False)
        print(f"ğŸ“ˆ è¨“ç·´çµæœå·²ä¿å­˜: {results_path}")
    
    # æœ€çµ‚æ¸¬è©¦
    print(f"\nğŸ§ª æœ€çµ‚æ¸¬è©¦...")
    try:
        test_env = SimpleFJSPEnv(batch_size, num_jobs, num_mas)
        final_result = validate_agent(test_env, agent)
        print(f"âœ… æœ€çµ‚æ¸¬è©¦æˆåŠŸï¼Makespan: {final_result:.4f}")
        
        # æ¸¬è©¦æ¨¡å‹ä¿å­˜è¼‰å…¥
        test_save_path = "./save/final_model.pt"
        torch.save(agent.model.state_dict(), test_save_path)
        
        new_agent = SimpleFJSPAgent()
        new_agent.model.load_state_dict(torch.load(test_save_path))
        print(f"âœ… æ¨¡å‹ä¿å­˜è¼‰å…¥æ¸¬è©¦æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ æœ€çµ‚æ¸¬è©¦å¤±æ•—: {e}")
    
    print("\nğŸŠ FJSP Transformer è¨“ç·´å®Œå…¨æˆåŠŸï¼")
    print("ğŸ“ æª¢æŸ¥ ./save/ ç›®éŒ„æŸ¥çœ‹æ‰€æœ‰ä¿å­˜çš„æ–‡ä»¶")
    
    return successful_iterations > 0

if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ… ç¨‹åºåŸ·è¡ŒæˆåŠŸï¼")
    else:
        print("\nâŒ ç¨‹åºåŸ·è¡Œå¤±æ•—ï¼")